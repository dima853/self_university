### **2.6 Modeling**  
 

## **1. Fundamentals of performance modeling**  
### **1.1 Why do I need modeling?**  
Modeling allows you to predict how the system will scale when:  
- Increased workload (users, requests).  
- Adding resources (CPU, memory, disks).  

**Three approaches to analysis:**  
1. **Observation** — measurements in the real system.  
2. **Experiments (Simulation)** — load tests.  
3. **Analytical Modeling** — mathematical models.  

**Important:** The best results are obtained by a combination of at least two methods.  

---

## **2. Knee Points (Critical Scalability Points)**  
### **2.1 What is Knee Point?**  
This is the moment when the system **stops scaling linearly** due to:  
- Competition for resources (blocking, contention).  
- Overhead costs for synchronization (coherence delay).  

### **2.2 Visualization example**  
Throughput graph (throughput) with increasing number of streams:  
```plaintext
Throughput (RPS)
   |
100 |               / 
    |             /  
 50 |           /   
    |         /    
  0 |_______/________
        8      16   Threads
```  
**Output:**  
- Up to **8 threads** — linear growth (perfect scaling).  
- After **8 threads** — growth slows down (knee point, hit the CPU/locks).  

### **2.3 How do I find Knee Point?**  
1. ** Experiment:** Running the test with a different number of threads.
2. **Analysis:** Search for the point where the `throughput` stops growing linearly.  

**Java example:**  
```java
ExecutorService executor = Executors.newWorkStealingPool();
IntStream.range(0, 1000).parallel().forEach(i -> {
    synchronized (this) { // Artificial lock
        compute(); // Operation
    }
});
```  
**Results:**  
| Streams | Throughput (RPS) |
| ------- | ---------------- |
| 1       | 100              |
| 4       | 400              |
| 8       | 700              | ← **Knee Point** |
| 16      | 750              |

---

## **3. Amdahl's Law**  
### **3.1 Formulation**  
**System acceleration is limited by a fraction of the sequential code (`α`):**  
```
C(N) = N / (1 + α(N – 1))
```  
- `N` is the number of threads/cores.  
- `α` is the fraction of the non—parallelizable code (0 ≤ α ≤ 1).  

### **3.2 Calculation example**  
If `α = 0.1` (10% of the code is sequential) and `N = 16`:
```
C(16) = 16 / (1 + 0.1*(16-1)) = 16 / 2.5 = 6.4x
```  
**Output:** Even with 16 cores, the acceleration is only **6.4x** (not 16x).  

### **3.3 Example in C**  
```c
#include <stdio.h>
#include <omp.h>

void serial_work() { 
    // 10% of the sequential code
    sleep(1); 
}

void parallel_work() {
    #pragma omp parallel for
    for (int i = 0; i < 1000; i++) {
// Parallel part
    }
}

int main() {
    double alpha = 0.1; // 10% sequential
    int N = omp_get_max_threads();
    double speedup = N / (1 + alpha * (N - 1));
    printf("Maximum acceleration: %.2fx\n", speedup);
    return 0;
}
```  

---

## **4. The Universal Law of Scalability (USL)**  
### **4.1 Formula**  
Takes into account **additional overhead costs (`β`)** for synchronization:
```
C(N) = N / (1 + α(N – 1) + βN(N – 1))
``` 
- `β` is the coherence coefficient (usually 0.001–0.01).  
♦️ The coherence coefficient, in simple words, shows how well two signals or processes are consistent in time and space.

### **4.2 Interpretation**  
- At `β = 0` → USL turns into Amdahl's law.  
- At `β > 0` → the system **degrades** faster due to overhead costs.  

**USL vs Amdahl schedule:**  
```plaintext
Throughput
    |
    | USL (β=0.01)  /
    |              / 
    | Amdahl     /  
    |          /   
    |________/______
         Threads
```  

---

## **5. Queuing Theory**  
### **5.1 M/D/1 (Disc model)**  
- **M** is the Poisson incoming flow.  
- **D** — Fixed maintenance time (deterministic).  
- **1** — One service center (disk).  

**Response time formula:**  
```
r = s * (2 - ρ) / (2 * (1 - ρ))
```  
- `s` — service time (for example, 2 ms).  
- `p` — disposal (0 ≤ p ≤ 1).  

**Example for Java:**  
```java
public class DiskLatency {
    public static void main(String[] args) {
        double rho = 0.6; // 60% disk load
        double s = 2.0; // 2 ms per operation
        double responseTime = s * (2 - rho) / (2 * (1 - rho));
        System.out.println("Average delay: " + responseTime + "ms");
    }
}
```  
**Output:**  
- At **60% load** → **4 ms** (2 times worse than at 0%).  
- At **80% load** → **10 ms** (5 times worse!).  

### **5.2 Why is 60% critical?**  
- After **60%**, the delay increases **non-linearly**.  
- For the 90th percentile:
``
  r_90 ≈ s * (1 + p + sqrt(2ρ(1-p))) / (1-p)
``
- For `p=0.8` → `r_90 ≈ 20 ms` (10 times worse!).  

---

## **6. Conclusions**  
1. **Knee Point** — the point where the system stops scaling linearly.  
2. **Amdahl's law** is a limitation due to the sequential code (`α`).  
3. **USL** — adds overhead accounting (`β`).  
4. **M/D/1** — The disk model shows why **60% loading is dangerous**.