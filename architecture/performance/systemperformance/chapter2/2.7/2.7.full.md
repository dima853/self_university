 2.7.1 Resource Limits: Search for bottlenecks in the system**  

This method helps to find a **resource** that will become a **bottleneck** under load. For containers, the restriction can be imposed **programmatically**.  

## 🎯 **The steps for this method are:**
1. Measure the rate of server requests, and monitor this rate over time.
2. Measure hardware and software resource usage. Monitor this rate over time.
3. Express server requests in terms of resources used.
4. Extrapolate server requests to known (or experimentally determined) limits for each
resource.

## 🔄 **Step 1: Measuring Server requests**  
- We measure ** the number of requests per second (RPS)**.  
- We are monitoring this indicator ** in dynamics**.  

## 📈 **Step 2: Resource Monitoring**  
We monitor the use of:
- **Hardware resources**:
- CPU (%)
- Memory (RAM)
- Disk IOPS, bandwidth, volume
- Network bandwidth  
- **Software resources**:
- Virtual memory  
  - Number of processes/threads  
  - Open file descriptors  

## 🔢 **Step 3: Linking Requests to Resources**  
We express **requests through consumed resources**.  

### 📐 **Calculation example for CPU**  
- The server processes **1000 RPS**.  
- **16 CPU** loaded at **40%**.  

**CPU% per request:**  
\[
\frac{16 \times 40\%}{1000} = 0.64\% \ text{ CPU/request}
\]

**Maximum throughput:**  
\[
\frac{100\% \times 16}{0.64\%} = 2500 \text{ RPS}
\]  

**Output:**  
At **2500 RPS** the CPU will reach **100%**.

![alt text](/architecture/performance//systemperformance//chapter2/images/9.png)

> ⚠️ This is **an optimistic assessment** - other resources may become a limitation sooner.  

---

**2.7.2 Factor Analysis: Cost and performance optimization**  

When deploying new systems, you can **vary the parameters** to find a balance between **performance** and **cost**.  

## 🔧 **Configuration testing method**  
1. **We are testing the system in the maximum configuration**.  
2. **We consistently reduce the parameters** and measure the drop in performance.  
3. **We evaluate the impact of each factor** on productivity.  
4. **We select the configuration** that provides the desired performance at the lowest cost.  

### 📊 **Example: Data Warehouse**  
| Parameter              | Performance drop | Savings |
| ---------------------- | ---------------- | ------- |
| 2 CPU instead of 4     | -30%             | ✅       |
| 1 network card         | -25%             | ✅       |
| Disabling jumbo frames | -35%             | ✅       |
| Enabling encryption    | -10%             | ❌       |
| Enabling compression   | -40%             | ❌       |
| RAM reduction          | -90%             | ✅       |

**Calculation for 1 GB/s:**  
\[
2 \times (1 - 0.30) \times (1 - 0.25) = 1.04 \text{ GB/s}
\]  

**Output:**  
The configuration **with 2 CPUs and 1 network card** gives **1.04 GB/s** — enough for the requirements.  

---

**2.7.3 Scaling Solutions: Horizontal and vertical scaling**  

## 📏 **Vertical scaling (Scale Up)**  
- Increase **server power** (CPU, RAM, disks).  
- **Positive:** Easy to manage.  
- **Minuses:** Expensive, there are physical limitations.  

## ↔️ **Horizontal scaling (Scale Out)**  
- Load balancing **between multiple servers**.  
- **Positive:** Flexibility, fault tolerance.  
- **Minuses:** The complexity of synchronization (for example, for a database).  

### ☁️ **Autoscaling in the cloud (AWS ASG, Kubernetes HPA)**  
- **AWS Auto Scaling Group (ASG)** — scales instances by CPU (for example, Netflix keeps **60%** of downloads).  
- **Kubernetes Horizontal Pod Autoscaler (HPA)** — automatically increases/decreases the number of pods.  

### 🗄️ **Database sharding**  
- Separation of data **by key** (for example, by the first letter of the user name).  
- **Critical:** Selection of **uniform sharding key** to avoid load skew.  

---

## 🎯 **Conclusions**  
1. **Resource Limits** — find the **bottleneck** through monitoring.
2. **Factor Analysis** — optimize **price/performance**.
3. **Scaling Solutions** — choose **horizontal** or **vertical** scaling.  

> **"It's better to test it once than to guess on coffee grounds!"** ☕🔍