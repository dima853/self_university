# 🚀 **Chapter 2: Presentation and processing of information**  
**Bits, numbers, and the magic of computer arithmetic** 🔢💻  

---

## **🔍 Basic concepts**  
### **1. The binary world of computers**  
- **Bit** is the minimum unit of information (0 or 1).  
- **Why the bits?** They are easily coded:
- 🔌 Voltage: *High (1) / low (0)*.  
   Magnetic domains: *left (0) / right (1)*.  

> 💡 **Historical fact:* The decimal system (0-9) appeared in India, and the Arabs and Fibonacci popularized it. But computers have chosen the binary system — it is ideal for electronics!  

### **2. Number Representation**
| Number type                | Encoding                              | Problem Example                        |
| -------------------------- | ------------------------------------- | -------------------------------------- |
| **Unsigned**               | Classical binary notation.            | `uint8_t` → 0..255.                    |
| **Addition to 2**          | The standard for signed integers.     | `int8_t` → -128..127.                  |
| **Floating point numbers** | Scientific notation in binary system. | `0.1 + 0.2 != 0.3` ( margin of error). |

---

## **⚡ Problems of computer arithmetic**  
### **🔹 Overflow**  
```c
int32_t x = 200 * 300 * 400 * 500; // Result: -884,901,888
```  
** Why?**  
- The product exceeds `INT_MAX' (2,147,483,647).  
- 2's complement → the highest bit becomes **1** (negative number).  

### **🔹 Properties of arithmetic**  
- **Integer**: Associative (`(a+b)+c == a+(b+c)`), but overflows are possible.  
- **Floating point**: Not associative due to rounding!  
  ``c
(3.14 + 1e20) - 1e20 == 0.0; // 1e20 "absorbs" 3.14
3.14 + (1e20 - 1e20) == 3.14; // Expected result.
  ```  

---

## **🔧 Examples of encodings**  
### **1. Addition to 2 (Two's Complement)**  
How to get `-5` in 8-bit representation:  
1. Binary type `5': `00000101'.  
2. Invert the bits: `11111010'.
3. Add 1: `11111011` (this is `-5`).  

**Verification:**  
```python
>>> int('11111011', 2) - 256 # 8- th bit = -128
-5
```  

### **2. Floating Point (IEEE 754)**  
The number `0.15625' in binary scientific notation:  
- Normalized form: `1.25 × 2-3'.  
- Encoding (32 bits):  
  ```
  Sign: 0 (+)
Exponent: 124 (127 - 3 = 124 → 01111100)
Mantissa: 01000000000000000000000 (1.25 → 0.01 in binary fraction)
``  

---

## **💡 Why is this important?**  
1. **Security**
- Buffer overflow → vulnerabilities (for example, Heartbleed).  
   - *Example:* If the program does not check the boundaries of the numbers, the hacker can overwrite the memory.  

2. **Code portability**
- In C/C++, the size of an `int' depends on the architecture (16/32/64 bits).  
   - In Java, everything is strict: `int` is always 32 bits.  

3. **Optimization**
- Understanding bit operations speeds up the code:
``c
     // Quick parity check:
     if (x & 1) { /* odd */ }
``  

---

## **📊 Language comparison**  
| Language | Integer types                                   | Floating point                      |
| -------- | ----------------------------------------------- | ----------------------------------- |
| **C**    | Depends on the platform (`int16_t`, `int32_t`). | IEEE 754 (but the behavior varies). |
| **Java** | Strict specification (`int' = 32 bits).         | Strictly IEEE 754.                  |

---

## **🎯 Conclusions**
* **Bits rule the world** — everything in computers boils down to 0 and 1.
* **Overflow and rounding** are sources of bugs and vulnerabilities.  
***Knowledge of encodings** helps you write fast and secure code.  

"Computer arithmetic is magic until you understand the bits!"*  

**🚀 Next:** Go deeper into assembler and optimization (Chapter 3)!

# 🚀 **Chapter 2.1: Storing information in computers**  
**Hexadecimal numbers, bits, and the evolution of the C language** 💾🔢  

---

## **🔍 Basic concepts**  
### **1. Hexadecimal system (Hex)**  
- **Why Hex?** Convenient for compact recording of bit sequences.  
  - 1 hex digit = 4 bits (for example, `0xF' = `1111`).  
  - Example: `OxFA1D37B` is a 32-bit number.  

**Translation table:**  
| Hex | Binary | Decimal |
| --- | ------ | ------- |
| `0` | `0000` | 0       |
| `A` | `1010` | 10      |
| `F` | `1111` | 15      |

**Examples:**  
```c
Ox1A3 = 0001 1010 0011 (binary) = 419 (decimal)
``

---

### **2. Conversion between systems**  
#### **🔹 Hex → Binary**  
We split each hex digit into 4 bits:
``  
Ox39A7F8 → 0011 1001 1010 0111 1111 1000  
```  

#### **🔹 Binary → Hex**  
We group the bits by 4 (from the end) and translate:
``  
1100100101111011 → 1100 1001 0111 1011 → OxC97B  
```  

#### **🔹 Decimal → Hex**  
Divide the number by 16 and collect the remainder:
``
314,156 - 16 = 19,634 (remainder 12 → 'C')
19,634 - 16 = 1,227 (remainder 2 → '2')  
... → Ox4CB2C  
```  

---

## **📜 The evolution of the C language**  
### **1. Key milestones**  
| Version      | Year | Key Features                        |
| ------------ | ---- | ----------------------------------- |
| **K&R C**    | 1978 | The first version (Bell Labs).      |
| **ANSI C89** | 1989 | Standardization, `void*`, `const'.  |
| **C99**      | 1999 | `long long`, `bool`, `//`-comments. |
| **C11**      | 2011 | Multithreading, `_Generic'.         |

### **2. How do I specify the version in GCC?**  
```bash
gcc -std=c99 program.c# Compilation in the C99 standard  
gcc -std=c11 program.c# C11 (default in modern GCC)  
```

---

## **🧩 Practical tasks**  
### **1. Number conversion**
**A. Ox39A7F8 → Binary**  
```
3 → 0011  
9 → 1001  
A → 1010  
... → 001110011010011111111000  
```  

**B. 1100100101111011 → Hex**  
```
1100 1001 0111 1011 → OxC97B  
```  

### **2. Arithmetic in Hex**
**A. Ox503C + Ox8 = Ox5044**  
```  
  503C  
+    8  
------  
  5044  
```  

**B. Ox50EA - Ox503C = OxAE**  
```  
  50EA  
- 503C  
------  
    AE  
```  

---

## **💡 Why is this important?**  
✅ **Understanding bit representations** is the key to low—level programming.  
 The hexadecimal system** is used in debuggers (GDB), memory dumps, and network protocols.  
✅ **C** standards affect the portability of code between platforms.  

> *"Hex is a bridge between human—readable and machine-readable data representation!"*  

**🚀 Next:** Pointers and memory management in C!